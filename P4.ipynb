{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc256d7a-8433-4487-a911-64caf1d06ead",
   "metadata": {},
   "source": [
    "# Práctica 3 y 4 - Sistemas Multimedia\n",
    "### Autor: Álvaro González Antequera\n",
    "### Fecha: 05/03/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd543f1-2dcc-47b8-810a-6cb29e9b2dc7",
   "metadata": {},
   "source": [
    "## Tarea 3 Parte 1:\n",
    "#### 1. He creado en GitHub un repositorio vacío y lo he clonado en mi ordenador con el comando ``` git clone (url de mi repositorio) ```.\n",
    "#### 2. He creado un entorno de conda con el comando ```conda create --name=Practica3```.\n",
    "#### 3. He creado dentro de mi repositorio local el archivo .gitignore y le he añadido la linea \".ipynb_checkpoints/\" para que se ignore dicha carpeta.\n",
    "#### 4. He activado el entorno de conda creado con el comando ```conda activate Practica3```.\n",
    "#### 5. He instalado Python, ipykernel y JupyterLab con el comando ```conda install -c conda-forge <package_name>```.\n",
    "#### 6. He añadido el entorno conda a los kernels de JupyterLab con el comando ```python3 -m ipykernel install --user --name=Practica3```.\n",
    "#### 7. Este paso lo realice en el ejercicio 5 con el comando ```conda install -c conda-forge JupyterLab```.\n",
    "#### 8. Para ejecutar JupyterLab, he ejecutado el comando ```jupyter-lab``` desde mi repositorio local."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4041f196-620e-461a-98f9-35028c0bc1b8",
   "metadata": {},
   "source": [
    "## Tarea 3 Parte 2:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87371f3c-805b-46a6-98fa-2374417d1c71",
   "metadata": {},
   "source": [
    "#### 1. He organizado el notebook utilizando recursos como #, ```, listas ordenadas, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd51be3-b309-4267-81b3-4630c892128b",
   "metadata": {},
   "source": [
    "#### 3. He cargado el audio estéreo y he mostrado sus características de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84e8b9b-638f-4891-8033-26d39ed97482",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install scipy #Instalación para que funcionen los import para cargar el audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab14ef3d-3cb3-4536-bd9c-db6fa9f8a5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install matplotlib #Instalación para que funcionen los import para crear la gráfica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4086ba2d-34fe-4465-9f3c-13af2fad4449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports:\n",
    "from scipy.io import wavfile\n",
    "import IPython\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087ed3f7-ff73-4aa5-9fcf-397f9fd6d371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se obtiene el directorio actual y se construyen las rutas al directorio de audios de entrada y de salida\n",
    "cwd = os.getcwd()\n",
    "Audios_input_path = os.path.join(cwd, os.path.join('Audios', '_input'))\n",
    "Audios_output_path = os.path.join(cwd, os.path.join('Audios', '_output'))\n",
    "print(f'Directorio con los audios de entrada: {Audios_input_path}')\n",
    "print(f'Directorio donde guardaremos los audios generados: {Audios_output_path}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79af5576-6a11-4e4a-9901-6b9d7862a17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se combina la ruta de entrada con el nombre del audio y se lee el archivo\n",
    "filename = os.path.join(Audios_input_path, 'interstellar.wav')\n",
    "sample_rate, audio_data = wavfile.read(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc293f65-51d6-47ea-805a-e81e18cfd310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se muestra la información del sonido estéreo.\n",
    "print('Datos de audio (estereo):')\n",
    "print(f'- Frecuencia de muestreo (sample rate): {sample_rate/1000} kHz')\n",
    "print(f'- Tamaño:     {audio_data.shape}')\n",
    "print(f'- 1º canal:   {audio_data[:5, 0]}...')\n",
    "print(f'- 2º canal:   {audio_data[:5, 1]}...')\n",
    "print(f'- Resolucion: {type(audio_data[0,0])}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017b34ed-1ab1-423c-b443-f302d9b5ffc7",
   "metadata": {},
   "source": [
    "#### 4. He incluido un widget para reproducir el audio estéreo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bee7c8-49bb-4e75-a961-a48dcd32b727",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(audio_data.T, rate=sample_rate) # Creación del widget para el audio estéreo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201f502c-f34f-4909-97e8-7e41db6a59ff",
   "metadata": {},
   "source": [
    "#### 5. Convierto el archivo de audio estéreo a mono y muestro sus características de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4e8301-c624-4255-af2c-bf3ce7530098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se convierte el audio estéreo a mono utilizando la media de los canales\n",
    "new_data_mono = audio_data.mean(axis=1)  # Calcula el promedio columna por columna\n",
    "print('Nuevos datos de audio (mono):')\n",
    "print(f'- Nuevo tamaño: {new_data_mono.shape}')\n",
    "print(f'- Canal unico:  {new_data_mono[:5]}...')\n",
    "\n",
    "# Se mantiene la misma resolución que el audio original\n",
    "new_data_mono = new_data_mono.astype(np.int16)\n",
    "print(f'- Resolucion:   {type(new_data_mono[0])}')\n",
    "print(f'- Frecuencia de muestreo (sample rate): {sample_rate/1000} kHz\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9265c8-8b31-4c0d-9f33-388378ed0de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se guarda el archivo mono a un fichero de tipo wav.\n",
    "wavfile.write(\n",
    "    filename=os.path.join(Audios_output_path, 'interstellar.wav'),\n",
    "    rate=sample_rate,\n",
    "    data=new_data_mono\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1019f0e5-4410-4f2d-b59e-09f058a1bc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se muestra el tamaño de los archivos\n",
    "!ls -sh Audios/_input/interstellar.wav\n",
    "!ls -sh Audios/_output/interstellar.wav"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444bb0ac-e154-4dd8-b0e6-7df245ae369c",
   "metadata": {},
   "source": [
    "#### 6. Vuelvo a incluir un widget, pero ahora para reproducir el audio mono:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522a8ee1-8ea7-49fe-92a0-6e436ef70083",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(new_data_mono, rate=sample_rate) #Creación del widget para el audio mono"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3356fd-e5a9-4c4f-9b35-7ec951ab7224",
   "metadata": {},
   "source": [
    "#### 7. Gráfica en el dominio del tiempo para el audio mono y estéreo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527299a2-13b2-418a-b91c-25b253457c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Configuración de la figura para graficar\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Grafica señal estéreo\n",
    "plt.subplot(2, 1, 1)\n",
    "if audio_data.ndim > 1:\n",
    "    for channel in range(audio_data.shape[1]):\n",
    "        plt.plot(audio_data[:, channel], label=f'Canal {channel + 1}')\n",
    "    plt.title('Señal de Audio Estéreo')\n",
    "else:\n",
    "    plt.plot(audio_data)\n",
    "    plt.title('Señal de Audio Estéreo (Canal Único)')\n",
    "plt.xlabel('Índice de Muestra')\n",
    "plt.ylabel('Amplitud')\n",
    "plt.legend()\n",
    "\n",
    "# Grafica señal mono\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(new_data_mono)\n",
    "plt.title('Señal de Audio Mono')\n",
    "plt.xlabel('Índice de Muestra')\n",
    "plt.ylabel('Amplitud')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ca02ec-ce6c-4092-be61-e444353271ed",
   "metadata": {},
   "source": [
    "#### 8. Diferencia entre audio estéreo y mono:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3591cab4-177f-46be-a458-3288742d4b01",
   "metadata": {},
   "source": [
    "Las principales diferencias entre audio estéreo y mono son:\n",
    "* El audio mono utiliza un único canal de mientras que el audio estéreo utiliza dos canales (izquierdo y derecho).\n",
    "* El audio estéreo al utilizar dos canales produce un sonido con sensación de profundidad y más envolvente que el mono, el cuál produce el mismo sonido para varios altavoces.\n",
    "* El audio estéreo se usa para entretenimiento y escuchar música y el mono para cuando se prefiere un sonido más simple y claro.\n",
    "* Debido a todo lo anterior el audio mono es menos costoso que el audio estéreo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a55393-8dd9-4509-893c-1612b0f24ce4",
   "metadata": {},
   "source": [
    "## Tarea 4:\n",
    "#### 2. Gráfica en el dominio del tiempo para el audio mono y estéreo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7458b5d4-eac2-4af5-a3f6-9f28e11e1bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se obtiene el número de muestras de cada audio\n",
    "ampl_estereo = len(audio_data)\n",
    "ampl_mono = len(new_data_mono)\n",
    "print(f'Número de muestras del audio estéreo (valores de amplitud): {ampl_estereo}')\n",
    "print(f'Número de muestras del audio mono (valores de amplitud): {ampl_mono}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55c7036-5a65-43f8-b4a5-bdd505a21cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se construye el array para el eje x que representa el tiempo de la grabación\n",
    "tEstereo = np.arange(0, ampl_estereo/sample_rate, 1/sample_rate)\n",
    "tMono = np.arange(0, ampl_mono/sample_rate, 1/sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c6aea6-54cb-4c68-bf21-4f694d50db5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea la figura.\n",
    "fig, ax = plt.subplots(2, 1, figsize=(12, 6), sharex=True)\n",
    "\n",
    "# Solo se muestran las primeras 50 muestras de amplitud (por claridad).\n",
    "end = 50\n",
    "\n",
    "# Señal estéreo (2 canales)\n",
    "ax[0].plot(tEstereo[:end], audio_data[:end, 0], marker='X', color='tab:blue', label='Canal 1')\n",
    "ax[0].plot(tEstereo[:end], audio_data[:end, 1], marker='o', color='tab:orange', label='Canal 2')\n",
    "ax[0].set_title(f'Audio estéreo en el dominio del tiempo muestreado a {sample_rate} Hz')\n",
    "ax[0].set_ylabel('Amplitud')\n",
    "ax[0].grid(True)\n",
    "ax[0].legend()\n",
    "\n",
    "# Señal mono (se utiliza el ratio para ajustar el eje X)\n",
    "ratio = sample_rate / sample_rate  \n",
    "ax[1].plot(tMono[:int(end/ratio)], new_data_mono[:int(end/ratio)], c='tab:red', marker='X')\n",
    "ax[1].set_title(f'Audio mono en el dominio del tiempo muestreado a {sample_rate} Hz')\n",
    "ax[1].set_xlabel('Tiempo (s)')\n",
    "ax[1].set_ylabel('Amplitud')\n",
    "ax[1].grid(True)\n",
    "\n",
    "# Se muestra la figura.\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291fa3af-bf0a-4697-91ef-289f071f2a25",
   "metadata": {},
   "source": [
    "#### 3. Explicación de frecuencia de muestreo, aliasing, profundidad de bits, ancho de banda y tasa de bits:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d528ad47-be84-4905-9fcf-779ced1571d7",
   "metadata": {},
   "source": [
    "* Frecuencia de muestreo: Es el número de muestras de audios que se toman por segundo al convertir un sondio analógico en digital. Mientras más alta sea más precisa es la representación del sonido original.\n",
    "* Aliasing: Es lo que ocurre cuando la frecuencia de muestreo es demasiado baja para capturar con precisión las frecuencias altas de un audio, esto provoca que se distorsionen.\n",
    "* Profundidad de bits: Es el número de bits que se usan para representar cada muestra de audio. \n",
    "* Ancho de banda: Es el rango de frecuencias que puede reproducir o grabar un sistema. Mientras mayor sea el ancho de banda mayor es el número de frecuencias que se pueden reproducir.\n",
    "* Tasa de bits: Es la cantidad de datos de audio transmitidos por segundo. A más tasa de bits más calidad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5eed4d7-f9f5-49ea-8e85-e0fad1dcf683",
   "metadata": {},
   "source": [
    "#### 4. Transformada rápida de Fourier (FFT) aplicada a un audio mono para cambiar al dominio de la frecuencia. Gráfica y por qué:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8221e5d1-4a71-4760-b3a9-b9de3f2e234a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se obtiene la longitud del array de datos y el sample rate (frecuencia de muestreo).\n",
    "n = len(new_data_mono)\n",
    "Fs = sample_rate\n",
    "\n",
    "# Se calcula la Transformada Rapida de Fourier (FFT) en audio mono.\n",
    "ch_Fourier = np.fft.fft(new_data_mono)\n",
    "\n",
    "# Solo se mira la frecuencia por debajo de Fs/2\n",
    "# (Nyquist-Shannon) --> Spectrum.\n",
    "abs_ch_Fourier = np.absolute(ch_Fourier[:n//2])\n",
    "\n",
    "# Se muestra la gráfica.\n",
    "plt.plot(np.linspace(0, Fs/2, n//2), abs_ch_Fourier)\n",
    "plt.ylabel('Amplitud', labelpad=10)\n",
    "plt.xlabel('$f$ (Hz)', labelpad=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b1010d-34c7-4640-89b7-9c84d25c9052",
   "metadata": {},
   "source": [
    "La FFT se aplica para descomponer un audio en sus componentes de frecuencia básicos y así poder entender mejor sus componentes individuales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4030ab95-a086-44a4-a6e1-1a1528f1ef44",
   "metadata": {},
   "source": [
    "#### 5. Energía del espectrograma y frecuencia de corte (con un epsilon):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5e1e91-796a-466f-90fa-68524b6c922d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se definen diferentes epsilons: la parte de la energia del espectro que NO se conserva.\n",
    "eps = [1e-5, .02, .041, .063, .086, .101, .123, .269]\n",
    "\n",
    "# Se va variando los valores de epsilon.\n",
    "eps = eps[7]\n",
    "print(f'Epsilon: {eps}')\n",
    "\n",
    "# Se calcula el valor de corte para esta energía.\n",
    "thr_spec_energy = (1 - eps) * np.sum(abs_ch_Fourier)\n",
    "print(f'Valor de corte para la energía del espectro: {thr_spec_energy}')\n",
    "\n",
    "# Integral de la frecuencia --> energía del espectro.\n",
    "spec_energy = np.cumsum(abs_ch_Fourier)\n",
    "\n",
    "# Máscara (array booleano) que compara el valor de corte con la energía del espectro.\n",
    "frequencies_to_remove = thr_spec_energy < spec_energy  \n",
    "print(f'Mascara: {frequencies_to_remove}')\n",
    "\n",
    "# Frecuencia f0 por la que se corta el espectro.\n",
    "f0 = (len(frequencies_to_remove) - np.sum(frequencies_to_remove)) * (Fs/2) / (n//2)\n",
    "print(f'Frecuencia de corte f0 (Hz): {int(f0)}')\n",
    "\n",
    "# Se muestra la gráfica\n",
    "plt.axvline(f0, color='r')\n",
    "plt.plot(np.linspace(0, Fs/2, n//2), abs_ch_Fourier)\n",
    "plt.ylabel('Amplitud')\n",
    "plt.xlabel('$f$ (Hz)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702c7f9c-512e-4dde-8dbc-11aa81c7cf9a",
   "metadata": {},
   "source": [
    "#### 6. Comprimo la onda aplicando downsampling (el factor se obtiene a partir de la frecuencia de corte):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e717f403-8222-44fb-a31a-4b329ff39878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se definen los nombres de los audios comprimidos.\n",
    "wav_compressed_file = \"interstellar_compressed.wav\"\n",
    "\n",
    "# Se calcula el factor D de downsampling.\n",
    "D = int(Fs / f0)\n",
    "print(f'Factor de downsampling: {D}')\n",
    "\n",
    "# Se obtienen los nuevos datos (slicing with stride).\n",
    "new_data = new_data_mono[::D]\n",
    "\n",
    "# Se escriben los datos a un archivo de tipo wav.\n",
    "wavfile.write(\n",
    "    filename=os.path.join(Audios_output_path, wav_compressed_file),\n",
    "    rate=int(Fs/D),\n",
    "    data=new_data\n",
    ")\n",
    "\n",
    "# Se carga el nuevo archivo.\n",
    "new_sample_rate, new_audio_data = wavfile.read(filename=os.path.join(Audios_output_path, wav_compressed_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ee439a-4d87-4697-8a26-ac8d14d969a6",
   "metadata": {},
   "source": [
    "#### 7. Espectograma de ambas ondas: original y comprimida. Diferencias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012b3c72-425a-4f7a-ae84-9ad0e6f54345",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1, figsize=(12, 8), sharex=True)\n",
    "\n",
    "Pxx, freqs, bins, im = ax[0].specgram(new_data_mono, NFFT=1024, Fs=sample_rate, noverlap=512)\n",
    "ax[0].set_title('Espectograma del audio original')\n",
    "ax[0].set_ylabel('Frecuencia (Hz)')\n",
    "ax[0].grid(True)\n",
    "\n",
    "Pxx, freqs, bins, im = ax[1].specgram(new_audio_data, NFFT=1024, Fs=new_sample_rate, noverlap=512)\n",
    "ax[1].set_title('Espectrograma del audio reducido/comprimido')\n",
    "ax[1].set_xlabel('Tiempo (s)')\n",
    "ax[1].set_ylabel('Frecuencia (Hz)')\n",
    "ax[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180d0c58-e1a5-4c82-a48a-07e90bbd5232",
   "metadata": {},
   "source": [
    "La principal diferencia que se aprecia es que el original muestra información en un rango de frecuencia mayor, se ve más intensidad en los colores y más detallado el original."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2247f9-6416-47ea-bd9f-ac62c7d92e7b",
   "metadata": {},
   "source": [
    "#### 8. Tamaño de ambos archivos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5060708e-2ce4-492b-9d5a-5df7ea99f5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Tamaño audio mono original:')\n",
    "!ls -sh Audios/_input/interstellar.wav\n",
    "print('Tamaño audio mono comprimido:')\n",
    "!ls -sh Audios/_output/interstellar_compressed.wav"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e8c228-99d8-4922-9b94-c0a099a25481",
   "metadata": {},
   "source": [
    "#### 9. Widgets para reproducir los audios original y comprimido:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5ef355-e40f-462d-9d2f-f5e59a97f510",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Audio mono original:')\n",
    "IPython.display.Audio(new_data_mono, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641e44b3-b2b1-48c6-9896-d15b6c1acc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Audio mono comprimido:')\n",
    "IPython.display.Audio(new_audio_data, rate=new_sample_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Practica3",
   "language": "python",
   "name": "practica3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
